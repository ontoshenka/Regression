{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ~~Наконец-то~~ Перебираем модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-первых, определим метрику"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_log_error as MSLE\n",
    "\n",
    "def RMSLE(y_true, y_pred):\n",
    "    return np.sqrt(MSLE(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Во-вторых, определим небольшой класс, который призван записывать информацию о валидации, дабы, как минимум, в будущем не потерять хорошую модель"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import math\n",
    "\n",
    "class Logger:\n",
    "    def __init__(self, estimator = 'XGBClassifier', eda_info = 'Нет', \n",
    "                 val_info = '10 блоков, без стандартизации, без PCA',\n",
    "                 grid = None, best_params = None, comp_info = 'Сравнивались средние значения',\n",
    "                 scores = None, outfile = r'logs\\log_1.txt'):\n",
    "        \n",
    "        '''\n",
    "        \n",
    "        Параметры:\n",
    "            estimator (str): Название модели\n",
    "            \n",
    "            eda_info (str): Информация о предобработке данных. Например, 'предварительно с помощью некоторого\n",
    "                            алгоритма были удалены выбросы'\n",
    "            \n",
    "            val_info (str): Информация о валидации: кол-во блоков, использование стандартизации и т.д\n",
    "            \n",
    "            grid (dict): Сетка, по которой перебирались гиперпараметры \n",
    "            \n",
    "            best_params (dict): Набор параметров, показавший себя лучше остальных \n",
    "            \n",
    "            comp_info (str): Информация о том, как в процессе валидации сравнивались модели с разными параметрами\n",
    "            \n",
    "            scores (numpy.ndarray, tuple): Набор значений метрики лучшей модели по время валидации или кортеж вида\n",
    "                                         (среднее значение, стандартное отклонение)\n",
    "            \n",
    "            outfile (str): Путь к файлу, в который вся информация будет записана \n",
    "        \n",
    "        Возвращаемое значение:\n",
    "            Объект класса \n",
    "        \n",
    "        '''\n",
    "        \n",
    "        self.estimator = estimator\n",
    "        self.eda_info = eda_info\n",
    "        self.val_info = val_info\n",
    "        self.grid = grid\n",
    "        self.best_params = best_params\n",
    "        self.comp_info = comp_info\n",
    "        self.scores = scores\n",
    "        self.outfile = outfile\n",
    "        \n",
    "        # Частенько сетка состоит из одной точки, т.е просто проводится валидация с помощью функции\n",
    "        # для поиска по сетке, ибо я ленивая жопа и не написал функцию просто для валидации\n",
    "        # (что даже справедливо, ибо зачем)\n",
    "        # В общем, в таком случае будет лишним выводить и сетку, и лучшие параметры\n",
    "        # Так что заводим индикатор того, что сетка состоит из одной точки\n",
    "                               # Значения - это списки\n",
    "        self.only_validation = ( [type(i) for i in self.grid.values()] == [list] * len(self.grid) \n",
    "                                 and (math.prod([len(i) for i in self.grid.values()]) == 1) )\n",
    "        \n",
    "    def scores_info(self, num_of_tabs = 0):\n",
    "        '''Формирует информацию о метрике лучшей модели\n",
    "        \n",
    "        Параметры:\n",
    "            num_of_tabs (int): Количество табуляций перед каждой строкой\n",
    "        \n",
    "        Возвращаемое значение:\n",
    "            Строкa с информацией о метрике \n",
    "        \n",
    "        '''\n",
    "        tabs = '\\t' * num_of_tabs\n",
    "        info = ''\n",
    "        if type(self.scores) == np.ndarray:\n",
    "            info += f'{tabs}Точность: {self.scores.mean()} +- {self.scores.std()} (mean +- std)\\n'\n",
    "            info += f'{tabs}Худшая точность: {self.scores.max()}\\n'\n",
    "            info += f'{tabs}Медианная точность: {np.median(self.scores)}\\n'\n",
    "            info += f'{tabs}Лучшая точность: {self.scores.min()}\\n'\n",
    "        else:\n",
    "            info += f'{tabs}Точность: {self.scores[0]} +- {self.scores[1]} (mean +- std)\\n'\n",
    "\n",
    "        return info\n",
    "    \n",
    "    def print_grid(self, stream = sys.stdout):\n",
    "        '''Выводит информацию о сетке гиперпараметров в указанный поток'''\n",
    "        stream.write('Сетка:\\n')\n",
    "        for key, value in self.grid.items():\n",
    "            stream.write(f'\\t{key}: {value}\\n')\n",
    "                \n",
    "    def print_best_params(self, stream = sys.stdout):\n",
    "        '''Выводит информацию о лучшем наборе гиперпараметров в указанный поток'''\n",
    "        stream.write('Лучший набор параметров:\\n')\n",
    "        if self.only_validation:\n",
    "            stream.write('\\tСетка состоит из одной точки\\n')\n",
    "            return\n",
    "        \n",
    "        for key, value in self.best_params.items():\n",
    "            stream.write(f'\\t{key}: {value}\\n')\n",
    "    \n",
    "    def make_note(self, print_scores_info = True):\n",
    "        '''Записывает информацию в файл\n",
    "        \n",
    "        Параметры:\n",
    "            print_scores_info (bool): Если True, вывод информацию о лучшей модели ещё и в sys.stdout\n",
    "                                      Что (не) происходит в противном случае догадаться не сложно\n",
    "        \n",
    "        '''\n",
    "        with open(self.outfile, 'a') as out:\n",
    "            out.write(f'Модель:\\n\\t{self.estimator}\\n')\n",
    "            out.write(f'Особенности предобработки данных:\\n\\t{self.eda_info}\\n')\n",
    "            out.write(f'Особенности валидации:\\n\\t{self.val_info}\\n')\n",
    "            self.print_grid(stream = out)\n",
    "            self.print_best_params(stream = out)\n",
    "            out.write(f'Информация о методе сравнения моделей:\\n\\t{self.comp_info}\\n')\n",
    "            out.write(f'Информация о метрике:\\n{self.scores_info(num_of_tabs = 1)}\\n')\n",
    "            out.write('\\n\\n' + '*' * 75 + '\\n\\n')\n",
    "        \n",
    "        if print_scores_info:\n",
    "            print(self.scores_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В-третьих, в силу моего маниакального нежелания стандартизовать всю выборку разом, полезно иметь функцию, которая всё стандартизует, обучит модель, получить предсказания и \"разстандартизует\" всё как было"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def teach_and_predict(X_train, X_test, real_features, model, **params):\n",
    "    '''\n",
    "    Обучает модель model на X_train, делает предсказания на X_test\n",
    "    \n",
    "    Параметры: \n",
    "        X_train (pandas.DataFrame): Таблица для обучения\n",
    "\n",
    "        y_train (pandas.Series): Список значений целевой переменной для объектов из X_train\n",
    "\n",
    "        X_test (pandas.DataFrame): Таблица, для которой нужно предсказать целевую переменную\n",
    "\n",
    "        features_to_standard (list, tuple, pandas.Index): Список признаков, которые подлежат стандартизации\n",
    "\n",
    "        model: Что угодно, что имеет методы fit и predict \n",
    "\n",
    "        **params (dict): Словарь, в котором ключи - это названия гиперпараметров модели, а значения - значения \n",
    "                         гиперпараметров, извиняюсь за тавтологию\n",
    "                         \n",
    "    Возвращаемое значение:\n",
    "        Кортеж из двух элементов. Первый из них - обученная модель, второй - предсказания модели\n",
    "        для объектов из X_test\n",
    "    '''\n",
    "    train_mean = X_train[real_features].mean()\n",
    "    train_std = X_train[real_features].std()\n",
    "    X_train[real_features] = (X_train[real_features] - train_mean) / train_std\n",
    "\n",
    "    sp_mean = X_train['SalePrice'].mean()\n",
    "    sp_std = X_train['SalePrice'].std()\n",
    "    X_train['SalePrice'] = (X_train['SalePrice'] - sp_mean) / sp_std\n",
    "\n",
    "    test_mean = X_test[real_features].mean()\n",
    "    test_std = X_test[real_features].std()\n",
    "    X_test[real_features] = (X_test[real_features] - test_mean) / test_std\n",
    "\n",
    "    model = model(**params)\n",
    "    model.fit(X_train.drop('SalePrice', axis = 1), X_train['SalePrice'])\n",
    "\n",
    "    sp_pred = model.predict(X_test)\n",
    "    sp_pred = np.exp(sp_pred * sp_std + sp_mean)\n",
    "\n",
    "    X_train[real_features]  = X_train[real_features] * train_std + train_mean\n",
    "    X_train['SalePrice'] = X_train['SalePrice'] * sp_std + sp_mean\n",
    "    X_test[real_features] = X_test[real_features] * test_std + test_mean\n",
    "    \n",
    "    # модель возвращается на случай, если захочется \"залезть\" к ней вовнутрь \n",
    "    return model, sp_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В-третьих, пригодится функция для стандартизации обучающих и тестовых блоков по отдельности, которая после получения значения метрики вернёт данные к изначальному масштабу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def teach_and_predict_while_grid_search(X, y, train_index, test_index,\n",
    "                                        real_features, model, **params):\n",
    "    '''\n",
    "    Стандартизует отдельно обучающие блоки и отдельно тестовый блок. После обучает указанную модель \n",
    "    с указанными параметрами, считает скор и возвращает данные к исходному масштабу. По сути\n",
    "    то же, что и teach_and_predict, но принимает данные в удобном во время поиска по сетке\n",
    "    \n",
    "    Параметры: \n",
    "        X (pandas.DataFrame): Таблица с данными (без целевой переменной)\n",
    "\n",
    "        y (pandas.Series): Список значений целевой переменной\n",
    "        \n",
    "        train_index (list, numpy.ndarray, tuple): Список индексов тренировочного набора \n",
    "\n",
    "        test_index (list, numpy.ndarray): Список индексов тестового набора\n",
    "        \n",
    "        real_features (list, tuple, pandas.Index): Список признаков, которые подлежат стандартизации\n",
    "        \n",
    "        model: Что угодно, что имеет методы fit и predict \n",
    "        \n",
    "        **params (dict): Словарь, в котором ключи - это названия гиперпараметров модели, а значения - значения \n",
    "                         гиперпараметров. \n",
    "    '''\n",
    "    # Стандартизуем обучающие блоки\n",
    "    train_mean = X.iloc[train_index][real_features].mean(axis = 0)\n",
    "    train_std = X.iloc[train_index][real_features].std(axis = 0)\n",
    "    X.loc[train_index, real_features] = (X.loc[train_index, real_features] - train_mean) / train_std\n",
    "    \n",
    "    # Стардартизуем тестовые блоки\n",
    "    test_mean = X.iloc[test_index][real_features].mean(axis = 0)\n",
    "    test_std = X.iloc[test_index][real_features].std(axis = 0)\n",
    "    X.loc[test_index, real_features] = (X.loc[test_index, real_features] - test_mean) / test_std\n",
    "\n",
    "    # Стандартизуем цены обучающего набора\n",
    "    train_sp_mean = y.loc[train_index].mean(axis = 0)\n",
    "    train_sp_std = y.loc[train_index].std(axis = 0)\n",
    "    y.loc[train_index] = (y.loc[train_index] - train_sp_mean) / train_sp_std\n",
    "\n",
    "    # Стандартизуем цены тестового набор\n",
    "    test_sp_mean = y.iloc[test_index].mean(axis = 0)\n",
    "    test_sp_std = y.iloc[test_index].std(axis = 0)\n",
    "    y.iloc[test_index] = (y.iloc[test_index] - test_sp_mean) / test_sp_std\n",
    "    \n",
    "    # Инициализируем модель\n",
    "    model = model(**params)\n",
    "    # Обучаем модель\n",
    "    model.fit(X.iloc[train_index], y.iloc[train_index])\n",
    "    \n",
    "    # Получаем предсказание модели на тестовой выборке\n",
    "    y_pred = model.predict(X.iloc[test_index])\n",
    "    # Масштабируем предсказания модели\n",
    "    y_pred = y_pred * test_sp_std[0] + test_sp_mean[0]\n",
    "    # Модели предсказывают логарифм цены\n",
    "    y_pred = np.exp(y_pred)\n",
    "    \n",
    "    # Возвращаем тестовые цены на место\n",
    "    y.iloc[train_index] = y.iloc[train_index] * train_sp_std + train_sp_mean\n",
    "    # Возвращаем на место цены тестового набора\n",
    "    y.iloc[test_index] = y.iloc[test_index] * test_sp_std + test_sp_mean\n",
    "\n",
    "    # Возвращаем на место обучащий блок\n",
    "    X.loc[train_index, real_features] = X.loc[train_index, real_features] * train_std + train_mean\n",
    "    # И тестовый тоже \n",
    "    X.loc[test_index, real_features] = X.loc[test_index, real_features] * test_std + test_mean\n",
    "    \n",
    "    return RMSLE(np.exp(y.iloc[test_index]), y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и в силу необходимости (а точнее, моего желания) стандартизировать блоки отдельно, придётся изобретать свой ~~велосипед~~ поиск по сетке. В этом, на самом деле, есть один заметный плюс: можно прикрутить tqdm, чтоб быть уверенным хотя бы в том, что перебираться всё это дело будет не до второго пришествия. Иными словами, даже если бы необходимости изобретать этот велосипед не было, его стоило бы изобрести"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import itertools\n",
    "# названия лучше не придумал\n",
    "def kosherGridSearchCV(X, y, model, param_grid, \n",
    "                       features_to_standard, comparator, rand_state,\n",
    "                       n_splits = 10):\n",
    "    '''\n",
    "    Проводит поиск лучших гиперпараметров по указанной сетке. \n",
    "    \n",
    "    Параметры: \n",
    "        X (pandas.DataFrame): Таблица с данными (без целевой переменной)\n",
    "\n",
    "        y (pandas.Series): Список значений целевой переменной\n",
    "        \n",
    "        model: Что угодно, что имеет методы fit и predict \n",
    "        \n",
    "        param_grid (dict): Словарь, описывающий все возможные гиперпараметры\n",
    "\n",
    "        features_to_standard (list, tuple, pandas.Index): Список признаков, которые подлежат стандартизации\n",
    "        \n",
    "        comparator (function): Функция, сравнивающая два массива. Должна возвращать отрицательное число,\n",
    "                               если первый список лучше второго в смысле выбранной метрики \n",
    "                               \n",
    "        rand_state (int): Ключ генератора случайных чисел для sklearn.KFold\n",
    "        \n",
    "        n_splits (int): Количество блоков, по которым будет проходить кросс-валидация\n",
    "    \n",
    "    Возвращаемое значение:\n",
    "        Кортеж из двух элементов. Первый из них - это словарь лучших гиперпараметров, \n",
    "        второй - значения точности модели на валидации\n",
    "    '''\n",
    "    cross_val = KFold(n_splits = n_splits, shuffle = True, random_state = rand_state)\n",
    "\n",
    "    best_params = {}\n",
    "    best_scores = np.array([1000] * n_splits) # Массив скоров, хуже которого быть не может\n",
    "\n",
    "    # общее число возможных комбинаций гиперпараметров\n",
    "    n_combs = math.prod([len(i) for i in param_grid.values()])\n",
    "    with tqdm(total = n_combs) as psbar: \n",
    "        for comb in itertools.product(*param_grid.values()):\n",
    "            cur_scores = np.array([])\n",
    "            # Получаем текущую комбинацию гиперпараметров\n",
    "            cur_params = { list(param_grid.keys())[i]: comb[i] for i in range(len(comb)) }\n",
    "            psbar.set_description(f'Processing {cur_params}')\n",
    "\n",
    "            for train_index, test_index in cross_val.split(X):\n",
    "                score = teach_and_predict_while_grid_search(X, y, train_index, test_index, features_to_standard,\n",
    "                                                            model, **cur_params)\n",
    "                cur_scores = np.append(cur_scores, score)\n",
    "\n",
    "            if comparator(cur_scores, best_scores) < 0:\n",
    "                best_scores = cur_scores\n",
    "                best_params = cur_params\n",
    "\n",
    "            psbar.update(1)\n",
    "\n",
    "    return best_params, best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_in_file(predictions, filename):\n",
    "    '''\n",
    "    Записывает предсказания в отдельный файл \n",
    "    '''\n",
    "    predictions = pd.DataFrame({'Id': [1461 + i for i in range(len(predictions))], 'SalePrice': predictions})\n",
    "    predictions.set_index('Id', inplace = True)\n",
    "    predictions.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Некоторые методы сравнения значений метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# для массивов с одинаковым средним вернёт 1, а не ноль, но малины это не портит\n",
    "def compare_means(a, b):\n",
    "    return -1 if a.mean() < b.mean() else 1\n",
    "\n",
    "def compare_diff_mean(a, b):\n",
    "    return (a - b).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загружаем обработанные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_x = pd.read_csv(r'processed_data\\train_df_x.csv')\n",
    "train_df_y = pd.read_csv(r'processed_data\\train_df_y.csv')\n",
    "test_df = pd.read_csv(r'processed_data\\test_df.csv')\n",
    "\n",
    "import pickle \n",
    "with open(r'processed_data\\features_to_standard.pickle', 'rb') as f:\n",
    "    features_to_standard = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df_x, train_df_y], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По непонятным мне причинам, после сохранения DataFrame'ов в файл, появляется вот такой вот странный столбец"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_x.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "train_df_y.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "train_df.drop('Unnamed: 0', axis = 1, inplace = True)\n",
    "test_df.drop('Unnamed: 0', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "EDA_INFO = 'Бейзлайн'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ну и последняя ремарочка: в роли отложенной выборки выступает его величество kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce317dd0b3a74beb8a9caaafa69c5ab2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/84 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.1317937560538709 +- 0.03629776491038654 (mean +- std)\n",
      "Худшая точность: 0.2325921659131279\n",
      "Медианная точность: 0.12493040643596987\n",
      "Лучшая точность: 0.08991501134870747\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso \n",
    "\n",
    "# Пандас истерически (и ложно) орёт, что я пытаюсь присвоить значение копии, а не представлению,\n",
    "# чем засоряет вывод \n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "lasso_param_grid = {'alpha': [0, 1e-2, 1e-3, 1e-4, 0.1, 0.5, 1, 2, 5, 10, 15, 20, 25, 50],\n",
    "                    'selection' : ['cyclic', 'random'],\n",
    "                    'fit_intercept': [False],\n",
    "                    'tol': [1e-3, 1e-4, 1e-5],\n",
    "                    'random_state': [42]}\n",
    "\n",
    "lasso_log = Logger(estimator = 'Lasso Regression',\n",
    "                   eda_info = EDA_INFO,\n",
    "                   val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                   grid = lasso_param_grid, outfile = r'logs\\linear_models.txt')\n",
    "\n",
    "lasso_log.best_params, lasso_log.scores = kosherGridSearchCV(train_df_x, train_df_y, Lasso,\n",
    "                                                             lasso_param_grid, features_to_standard,\n",
    "                                                             compare_means, 42, 10)\n",
    "\n",
    "lasso_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_model, lasso_pred = teach_and_predict(train_df, test_df, features_to_standard, Lasso, **lasso_log.best_params)\n",
    "\n",
    "write_in_file(lasso_pred, r'predictions\\lasso_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор на отложенной выборке - 0.13633"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c6ee23781b44f6c9f731e6318c88d9c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/126 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.13193543293520127 +- 0.03641122148624169 (mean +- std)\n",
      "Худшая точность: 0.23206353531799068\n",
      "Медианная точность: 0.12262096860856261\n",
      "Лучшая точность: 0.08931316252250326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "ridge_param_grid = {'alpha': [0.1, 0.5, 1, 2, 5, 10],\n",
    "                    'solver' : ['auto', 'svd', 'cholesky', 'lsqr', 'sparse_cg', 'sag', 'saga'], # запихнул всё шо было\n",
    "                    'fit_intercept': [False],                                                   # в документации\n",
    "                    'tol': [1e-3, 1e-4, 1e-5],                    \n",
    "                    'random_state': [42]}\n",
    "\n",
    "ridge_log = Logger(estimator = 'Ridge Regression',\n",
    "                   eda_info = EDA_INFO,\n",
    "                   val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                   grid = ridge_param_grid, outfile = r'logs\\linear_models.txt')\n",
    "\n",
    "ridge_log.best_params, ridge_log.scores = kosherGridSearchCV(train_df_x, train_df_y, Ridge,\n",
    "                                                             ridge_param_grid, features_to_standard,\n",
    "                                                             compare_means, 42, 10)\n",
    "\n",
    "ridge_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_model, ridge_pred = teach_and_predict(train_df, test_df, features_to_standard, Ridge, **ridge_log.best_params)\n",
    "\n",
    "write_in_file(ridge_pred, r'predictions\\ridge_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весьма и весьма. Скор на отложенной выборке - 0.13312"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32b2e6c64c6c4fbba5f6a1deb4420d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/396 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.13550165367055583 +- 0.03623419899809722 (mean +- std)\n",
      "Худшая точность: 0.2352251156265658\n",
      "Медианная точность: 0.1230004366864054\n",
      "Лучшая точность: 0.09397054232461638\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "\n",
    "elnet_param_grid = {'alpha': [0.05, 0.1, 0.2],\n",
    "                    'l1_ratio': [0, 0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1],\n",
    "                    'fit_intercept': [False],\n",
    "                    'tol': [1e-3, 1e-4, 1e-5],\n",
    "                    'selection': ['cyclic', 'random'],\n",
    "                    'positive': [True, False]}\n",
    "\n",
    "elnet_log = Logger(estimator = 'Elnet Regression',\n",
    "                   eda_info = EDA_INFO,\n",
    "                   val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                   grid = elnet_param_grid, outfile = r'logs\\linear_models.txt')\n",
    "\n",
    "elnet_log.best_params, elnet_log.scores = kosherGridSearchCV(train_df_x, train_df_y, ElasticNet,\n",
    "                                                             elnet_param_grid, features_to_standard,\n",
    "                                                             compare_means, 42, 10)\n",
    "\n",
    "elnet_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "elnet_model, elnet_pred = teach_and_predict(train_df, test_df, features_to_standard, ElasticNet, **elnet_log.best_params)\n",
    "\n",
    "write_in_file(elnet_pred, 'predictions\\elnet_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор на отложенной выборке - 0.14398"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9ac4723a2c5469995f14422637d3162",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/150 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.12589469667207256 +- 0.02592604722896134 (mean +- std)\n",
      "Худшая точность: 0.1934920766785683\n",
      "Медианная точность: 0.11966529093955239\n",
      "Лучшая точность: 0.09852807857039018\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "svr_param_grid = {'kernel': ['rbf'],\n",
    "                  'gamma': [1/50, 1/75, 1/100, 1/125, 1/150],\n",
    "                  'C': [1.5, 2.0, 2.5, 5, 10],\n",
    "                  'epsilon': [0.001, 0.005, 0.025, 0.05, 0.75, 1]}\n",
    "\n",
    "svr_log = Logger(estimator = 'SVR Regression',\n",
    "                   eda_info = EDA_INFO,\n",
    "                   val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                   grid = svr_param_grid, outfile = r'logs\\linear_models.txt')\n",
    "\n",
    "svr_log.best_params, svr_log.scores = kosherGridSearchCV(train_df_x, train_df_y, SVR,\n",
    "                                                         svr_param_grid, features_to_standard,\n",
    "                                                         compare_means, 42, 10)\n",
    "\n",
    "svr_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_model, svr_pred = teach_and_predict(train_df, test_df, features_to_standard, SVR, **svr_log.best_params)\n",
    "\n",
    "write_in_file(svr_pred, 'predictions\\svr_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Весьма и весьма неплохо. Скор на отложенной выборке - 0.13321"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**XGBoost**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пошла тяжёлая артиллерия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9bfe4472116e4b76a00668e846315e95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.13067738612674912 +- 0.027263880480026162 (mean +- std)\n",
      "Худшая точность: 0.194933948684656\n",
      "Медианная точность: 0.12786470287346788\n",
      "Лучшая точность: 0.08671168610621242\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "xgb_param_grid = {'booster': ['dart', 'gbtree'],\n",
    "                  'verbosity': [0],\n",
    "                  'max_depth': [6],\n",
    "                  'eta': [0.03],\n",
    "                  'n_estimators': [200, 500],\n",
    "                  'subsample': [0.3, 0.4],\n",
    "                  'colsample_bytree': [0.3, 0.4],\n",
    "                  'random_state': [42]}\n",
    "\n",
    "xgb_log = Logger(estimator = 'XGBRegressor',\n",
    "                 eda_info = EDA_INFO,\n",
    "                 val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                 grid = xgb_param_grid, outfile = r'logs\\tree_based_models.txt')\n",
    "\n",
    "xgb_log.best_params, xgb_log.scores = kosherGridSearchCV(train_df_x, train_df_y, XGBRegressor,\n",
    "                                                         xgb_param_grid, features_to_standard,\n",
    "                                                         compare_means, 42, 10)\n",
    "\n",
    "xgb_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model, xgb_pred = teach_and_predict(train_df, test_df, features_to_standard, XGBRegressor, **xgb_log.best_params)\n",
    "\n",
    "write_in_file(xgb_pred, r'predictions\\xgb_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор на отложенной выборке - 0.13710"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LightGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad85ba96cc6d4fffaefa29d0e9a575f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/144 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.13569009932119655 +- 0.024715423354863243 (mean +- std)\n",
      "Худшая точность: 0.18785189556012152\n",
      "Медианная точность: 0.13621359540738412\n",
      "Лучшая точность: 0.09072813964127918\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMRegressor\n",
    "\n",
    "lgb_param_grid = {'boosting_type': ['gbdt', 'goss'],\n",
    "                  'max_depth': [5, 6, 7],\n",
    "                  'learning_rate': [0.05, 0.01],\n",
    "                  'n_estimators': [150, 250, 500],\n",
    "                  'subsample': [0.3, 0.4],\n",
    "                  'colsample_bytree': [0.3, 0.4],\n",
    "                  'random_state': [42]}\n",
    "\n",
    "lgb_log = Logger(estimator = 'LGBMRegressor',\n",
    "                 eda_info = EDA_INFO,\n",
    "                 val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                 grid = xgb_param_grid, outfile = r'logs\\tree_based_models.txt')\n",
    "\n",
    "lgb_log.best_params, lgb_log.scores = kosherGridSearchCV(train_df_x, train_df_y, LGBMRegressor,\n",
    "                                                         lgb_param_grid, features_to_standard,\n",
    "                                                         compare_means, 42, 10)\n",
    "\n",
    "lgb_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_model, lgb_pred = teach_and_predict(train_df, test_df, features_to_standard, LGBMRegressor, **lgb_log.best_params)\n",
    "\n",
    "write_in_file(lgb_pred, r'predictions\\lgb_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор на отложенной выборке - 0.13732"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d77e87bc9b84f60bafdf19044407128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/36 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Точность: 0.14869504050569898 +- 0.02291633520711987 (mean +- std)\n",
      "Худшая точность: 0.19849275671574707\n",
      "Медианная точность: 0.1439176853871\n",
      "Лучшая точность: 0.10571954809850741\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "rf_param_grid = {'n_estimators': [750, 1000, 1250],\n",
    "                 'max_depth': [6, 7, 8],\n",
    "                 'max_features': [0.3, 0.5],\n",
    "                 'random_state': [42],\n",
    "                 'max_samples': [0.3, 0.5]}\n",
    "\n",
    "rf_log = Logger(estimator = 'RandomForestRegressor',\n",
    "                eda_info = EDA_INFO,\n",
    "                val_info = '10 блоков, со стандартизацией и PCA', \n",
    "                grid = xgb_param_grid, outfile = r'logs\\tree_based_models.txt')\n",
    "\n",
    "rf_log.best_params, rf_log.scores = kosherGridSearchCV(train_df_x, train_df_y, RandomForestRegressor,\n",
    "                                                       rf_param_grid, features_to_standard,\n",
    "                                                       compare_means, 42, 10)\n",
    "\n",
    "rf_log.make_note()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model, rf_pred = teach_and_predict(train_df, test_df, features_to_standard, RandomForestRegressor, **rf_log.best_params)\n",
    "\n",
    "write_in_file(rf_pred, r'predictions\\rf_preds.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скор на отложенной выборке крайне плох - 0.15959"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка целесообразности использования t-теста стьюдента для сравнения средних скоров"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Убедимся на будущее (для сравнения средних значений скоров t-тестом Стьюдента) в том, что скоры распределены нормально, а их дисперсии различаются статистически незначимо. $p_{value} = 0.05$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "\n",
    "def f_test(x, y):\n",
    "    x = np.array(x)\n",
    "    y = np.array(y)\n",
    "    # По умолчанию numpy считает смещённую оценку выборочной дисперсии. \n",
    "    # параметр ddof, приравненый к единице, исправляет это недоразумение \n",
    "    f_stat = np.var(x, ddof = 1) / np.var(y, ddof = 1) \n",
    "    dfn = x.size - 1 \n",
    "    dfd = y.size - 1 \n",
    "    p_value = 1 - scipy.stats.f.cdf(f_stat, dfn, dfd) \n",
    "    return f_stat, p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка нормальности:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Скоры XGBoost распределены нормально: True pvalue: 0.4042729437351227\n",
      "Скоры LightGBM распределены нормально: True pvalue: 0.7962411046028137\n",
      "Скоры Random Forest распределены нормально: True pvalue: 0.5831871628761292\n",
      "Скоры SVR распределены нормально: False pvalue: 0.03177593648433685\n",
      "Скоры Lasso распределены нормально: False pvalue: 0.0024544140323996544\n",
      "Скоры Ridge распределены нормально: False pvalue: 0.003651607548817992\n",
      "Скоры Elastic Net распределены нормально: False pvalue: 0.003158147446811199\n"
     ]
    }
   ],
   "source": [
    "xgb_pvalue = scipy.stats.shapiro(xgb_log.scores)[1]\n",
    "lgb_pvalue = scipy.stats.shapiro(lgb_log.scores)[1]\n",
    "rf_pvalue = scipy.stats.shapiro(rf_log.scores)[1]\n",
    "svr_pvalue = scipy.stats.shapiro(svr_log.scores)[1]\n",
    "lasso_pvalue = scipy.stats.shapiro(lasso_log.scores)[1]\n",
    "ridge_pvalue = scipy.stats.shapiro(ridge_log.scores)[1]\n",
    "elnet_pvalue = scipy.stats.shapiro(elnet_log.scores)[1]\n",
    "\n",
    "print('Скоры XGBoost распределены нормально:', xgb_pvalue > 0.05, 'pvalue:', xgb_pvalue)\n",
    "print('Скоры LightGBM распределены нормально:', lgb_pvalue > 0.05, 'pvalue:', lgb_pvalue)\n",
    "print('Скоры Random Forest распределены нормально:', rf_pvalue > 0.05, 'pvalue:', rf_pvalue)\n",
    "print('Скоры SVR распределены нормально:', svr_pvalue > 0.05, 'pvalue:', svr_pvalue)\n",
    "print('Скоры Lasso распределены нормально:', lasso_pvalue > 0.05, 'pvalue:', lasso_pvalue)\n",
    "print('Скоры Ridge распределены нормально:', ridge_pvalue > 0.05, 'pvalue:', ridge_pvalue)\n",
    "print('Скоры Elastic Net распределены нормально:', elnet_pvalue > 0.05, 'pvalue:', elnet_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Да, тест проводится лишь для лучших скоров каждой модели, но там, где $p_{value}$ больше 0.05, он, помимо всего прочего, значительно больше, чем 0.05, так что оснований считать, что скоры распределены нормально не всегда, нет "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверка равенство дисперсий"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Дисперсии XGBoost и LightGBM равны: True pvalue: 0.3873877548496365\n",
      "Дисперсии XGBoost и Random Forest равны: True pvalue: 0.30654736598608534\n",
      "Дисперсии LightGBM и Random Forest равны: True pvalue: 0.41276749272113566\n"
     ]
    }
   ],
   "source": [
    "xgb_lgb_pvalue = f_test(xgb_log.scores, lgb_log.scores)[1]\n",
    "xgb_rf_pvalue = f_test(xgb_log.scores, rf_log.scores)[1]\n",
    "lgb_rf_pvalue = f_test(lgb_log.scores, rf_log.scores)[1]\n",
    "print('Дисперсии XGBoost и LightGBM равны:', xgb_lgb_pvalue > 0.05, 'pvalue:', xgb_lgb_pvalue)\n",
    "print('Дисперсии XGBoost и Random Forest равны:', xgb_rf_pvalue > 0.05, 'pvalue:', xgb_rf_pvalue)\n",
    "print('Дисперсии LightGBM и Random Forest равны:', lgb_rf_pvalue > 0.05, 'pvalue:', lgb_rf_pvalue)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выводы аналогичны"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Таким образом, сравнение средних при помощи t-test'а оправдано "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
