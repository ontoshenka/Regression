# Структура проекта
- `data` - исходные данные
- `processed_data` - данные после EDA
- `predictions` - предсказания разных моделей на тестовом наборе
- `logs` - информация о испробованных моделях и условиях валидации. Удобно в случае, если когда-то получилась хорошая модель, но вспомнить как она получилась никак не выходит
- `EDA.ipynb` - некий бейзлайн разведочного анализа данных, изменения относительно предполагается  описывать в логах

# Что было сделано

- Проведён разведочный анализ данных
- Были проверены некоторые статистические гипотезы
- "Неудобно" распределённые вещественнозначные переменные, которые можно было привести к нормальному распределению, были к нему приведены, ибо ходят слухи, что это ещё никому не помешало
- Были сгенерированы новые вещественнозначные признаки
- Реализована своя функция для валидации по k блокам и поиска по сетка за тем, чтоб удобнее отслеживать прогресс выполнения (с помощью tqdm) и иметь возможность по необходимости расширять функционал, что пригодилось в другом проекте
- Был испробован ряд моделей, для каждой из которых был проведён тюнинг гиперпараметров. К сожалению, это не отражено ни в блокноте (ибо иначе получалось бы слишком громоздко), ни в логах (ибо догадался логировать я, к сожалению, уже во время работы над вышеуказанным проектом) 

# Грабли
В основном, все грабли были зашиты в фишки и тонкости работы с библиотеками. Ничего серьёзного, всё без проблем гуглится. Из конкретики - рекомендую почитать про копии и представления в пандас и разницу между обычной индексацией и индексацией через .loc и .iloc. Сделать это можно, например, [в документации](https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html)

# Чему я научился и что вынес в процессе работы
Сидеть и непонятно почему часами пытаться улучшить качество работы конкретного алгоритма исключительно через попытки тюнить гиперпараметры - не лучшая идея. Как правило, гораздо больше результатов дают эксперименты с предобработкой данных   

# Что можно сделать, чтоб улучшить результат 

1. Попробовать сравнивать модели другими методами (t-тест Стьюдента, сравнение с нулём попарных разностей скоров двух моделей).
2. Сгенерировать новые признаки
3. Поварьировать "агрессивность" отбора категориальных признаков